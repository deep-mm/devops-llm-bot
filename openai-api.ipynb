{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (23.3)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.5.0)\n",
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.28.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.28.1)\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.0/250.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2022.4)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (1.23.3)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (3.8.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests) (2022.9.24)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "\n",
    "%pip install pandas openai requests openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import openai\n",
    "import openpyxl\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the API key from a file\n",
    "def load_api_key(api_key_file_path):\n",
    "    with open(api_key_file_path, 'r') as file:\n",
    "        api_key = file.read().strip()\n",
    "    return api_key\n",
    "\n",
    "# Load your API key from a file\n",
    "api_key = load_api_key('api-key.txt')\n",
    "\n",
    "# Set up the OpenAI API client\n",
    "openai.api_key = api_key\n",
    "\n",
    "github_pat = load_api_key('github-pat.txt')\n",
    "headers = {'Authorization': 'token ' + github_pat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_response(user_prompt, system_message, model=\"gpt-3.5-turbo-16k\", max_tokens=1000):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"system\", \"content\": system_message},\n",
    "                  {\"role\": \"user\", \"content\": user_prompt}],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature = 0.2\n",
    "    )\n",
    "    return response.choices[0].message['content'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_build_pipeline(repo_structure, languages, dependencies):\n",
    "    system_message = \"Your name is Dev bot. You are a brilliant and meticulous engineer assigned to write a GitHub Actions workflow in YAML for the following Github Repository. When you write code, the code works on the first try, is syntactically perfect and is fully complete. The workflow should be able to build and run the application and run the tests if present in the repository. Take into account the current repository's language, frameworks, and dependencies. \"\n",
    "\n",
    "    user_prompt = \"\"\"\n",
    "    Analyze the github repository structure, language, framework and dependencies provide below to create a github action build workflow. You will provide the github action workflow as the answer. Only include the yaml file in the output. Do not add any other text before or after the code.\n",
    "    \n",
    "    Repository structure:\n",
    "    {repo_structure}\n",
    "\n",
    "    Languages: \n",
    "    {languages}\n",
    "\n",
    "    Dependencies: \n",
    "    {dependencies}\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    request_input = {\n",
    "        'repo_structure': repo_structure,\n",
    "        'languages': languages,\n",
    "        'dependencies': dependencies\n",
    "    }\n",
    "\n",
    "    user_prompt = user_prompt.format(**request_input)\n",
    "\n",
    "    response = get_chat_response(user_prompt=user_prompt, system_message=system_message)\n",
    "\n",
    "    return response.strip(\"```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repository_tree(repository_identifier, branch='main'):\n",
    "\n",
    "    repository_tree = []\n",
    "    response = requests.get(f'https://api.github.com/repos/{repository_identifier}/git/trees/{branch}', headers=headers)\n",
    "    data = response.json()\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        root_tree = data['tree']\n",
    "        max_depth = 2\n",
    "\n",
    "        def get_tree_recursive(tree_sha, current_depth):\n",
    "            if current_depth > max_depth:\n",
    "                return\n",
    "\n",
    "            response = requests.get(f'https://api.github.com/repos/{repository_identifier}/git/trees/{tree_sha}', headers=headers)\n",
    "            data = response.json()\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                for item in data['tree']:\n",
    "                    if item['type'] == 'tree':\n",
    "                        repository_tree.append(f\"Directory: {item['path']}\")\n",
    "                        get_tree_recursive(item['sha'], current_depth + 1)\n",
    "                    else:\n",
    "                        repository_tree.append(f\"File: {item['path']}\")\n",
    "\n",
    "        get_tree_recursive(data['sha'], 1)\n",
    "    else:\n",
    "        print(f\"Failed to fetch tree: {data['message']}\")\n",
    "\n",
    "    return repository_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_languages(repository_identifier):\n",
    "    url = 'https://api.github.com/repos/' + repository_identifier + '/languages'\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    return response.json().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_dependencies(repository_identifier):\n",
    "    url = 'https://api.github.com/repos/' + repository_identifier + '/dependency-graph/sbom'\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.json()['sbom']['packages']\n",
    "    dependency_names = [package['name'] + ', version = ' + package['versionInfo'] for package in response.json()['sbom']['packages']]\n",
    "    \n",
    "    return dependency_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_branch(repository_identifier):\n",
    "    url = 'https://api.github.com/repos/' + repository_identifier\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    return response.json()['default_branch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(csvFile):\n",
    "    for i in range(0,len(csvFile)):\n",
    "        repo_identifier = csvFile.iloc[i]['GitHub_Repo_Link'].split('github.com/')[1]\n",
    "        print(repo_identifier)\n",
    "        try:\n",
    "            repo_structure = get_repository_tree(repo_identifier, get_default_branch(repo_identifier))\n",
    "            languages = get_list_of_languages(repo_identifier)\n",
    "            dependencies = get_list_of_dependencies(repo_identifier)\n",
    "            csvFile.loc[i,'Generated_Build_Pipeline_File_Content'] = generate_build_pipeline(repo_structure, languages, dependencies)\n",
    "            # Add delay to avoid rate limiting\n",
    "            time.sleep(30)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "    csvFile.to_csv('DevOps_LLM_Bot_Test_Data - C#.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = 'DevOps_LLM_Bot_Test_Data.xlsx'\n",
    "excel = pandas.ExcelFile(excel_file)\n",
    "sheet_names = excel.sheet_names\n",
    "\n",
    "for sheet_name in sheet_names:\n",
    "    csv_file = sheet_name + '.csv'\n",
    "    df = pandas.read_excel(excel_file, sheet_name=sheet_name)\n",
    "    df.to_csv('data/'+csv_file, index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/subodhgujar/Desktop/GAI4SE/devops-llm-bot/openai-api.ipynb Cell 12\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/subodhgujar/Desktop/GAI4SE/devops-llm-bot/openai-api.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mglob\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/subodhgujar/Desktop/GAI4SE/devops-llm-bot/openai-api.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/subodhgujar/Desktop/GAI4SE/devops-llm-bot/openai-api.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m os\u001b[39m.\u001b[39;49mchdir(\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/subodhgujar/Desktop/GAI4SE/devops-llm-bot/openai-api.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m extension \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcsv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/subodhgujar/Desktop/GAI4SE/devops-llm-bot/openai-api.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m all_filenames \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m glob\u001b[39m.\u001b[39mglob(\u001b[39m'\u001b[39m\u001b[39m*.\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(extension))]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data'"
     ]
    }
   ],
   "source": [
    "for sheet_name in sheet_names:\n",
    "    csv_file = sheet_name + '.csv'\n",
    "    df = pandas.read_csv('data/'+csv_file)\n",
    "    print(\"Running experiment for sheet: \" + sheet_name + \" ... \")\n",
    "    run_experiment(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DapperLib/Dapper\n",
      "huiyadanli/RevokeMsgPatcher\n",
      "jasontaylordev/CleanArchitecture\n",
      "This model's maximum context length is 16385 tokens. However, your messages resulted in 27982 tokens. Please reduce the length of the messages.\n",
      "nilaoda/N_m3u8DL-CLI\n",
      "shadowsocks/shadowsocks-windows\n",
      "ShareX/ShareX\n",
      "DapperLib/Dapper\n",
      "aalhour/C-Sharp-Algorithms\n",
      "Cysharp/UniTask\n",
      "EduardoPires/EquinoxProject\n",
      "felixse/FluentTerminal\n",
      "graphql-dotnet/graphql-dotnet\n",
      "This model's maximum context length is 16385 tokens. However, your messages resulted in 25300 tokens. Please reduce the length of the messages.\n",
      "gui-cs/Terminal.Gui\n",
      "hellzerg/optimizer\n",
      "JeffreySu/WeiXinMPSDK\n",
      "jstedfast/MailKit\n",
      "JustArchiNET/ArchiSteamFarm\n",
      "kgrzybek/modular-monolith-with-ddd\n",
      "MahApps/MahApps.Metro\n",
      "MassTransit/MassTransit\n",
      "This model's maximum context length is 16385 tokens. However, your messages resulted in 39191 tokens. Please reduce the length of the messages.\n"
     ]
    }
   ],
   "source": [
    "run_experiment(csvFile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
